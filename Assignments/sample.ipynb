{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_API_KEY\")\n",
    "os.environ[\"OPENAI_API_KEY\"]=os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from typing import Annotated\n",
    "from langchain_core.messages import AnyMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import HumanMessage,SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm=ChatOpenAI(model='gpt-4o')\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages:Annotated[list[AnyMessage],add_messages]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the title generation function\n",
    "def title_generate(topic: str) -> str:\n",
    "    \"\"\"\n",
    "    Generates a catchy, informative, and creative title for an article based on the given topic.\n",
    "    \n",
    "    Args:\n",
    "        topic (str): The topic or subject for the article.\n",
    "    \n",
    "    Returns:\n",
    "        str: The generated title.\n",
    "    \"\"\"\n",
    "    prompt = f\"Generate a catchy, informative, and creative title for an article based on the following topic: {topic}\"\n",
    "    \n",
    "    response = llm.call_as_tool(\n",
    "        inputs=[HumanMessage(content=prompt)],\n",
    "        return_message=True  # Ensure you get the response\n",
    "    )\n",
    "    \n",
    "    title = response.content\n",
    "    return title\n",
    "\n",
    "# Define the content creation function\n",
    "def content_creator(title: str) -> str:\n",
    "    \"\"\"\n",
    "    Generates a detailed and engaging article based on the given title.\n",
    "    \n",
    "    Args:\n",
    "        title (str): The title of the article to generate content for.\n",
    "    \n",
    "    Returns:\n",
    "        str: The generated content for the article.\n",
    "    \"\"\"\n",
    "    prompt = f\"Generate a detailed and engaging article based on the following title: {title}\"\n",
    "    \n",
    "    response = llm.call_as_tool(\n",
    "        inputs=[HumanMessage(content=prompt)],\n",
    "        return_message=True  # Ensure you get the response\n",
    "    )\n",
    "    \n",
    "    content = response.content\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools=[title_generate,content_creator]\n",
    "llm_with_tools=llm.bind_tools(tools=tools,parallel_tool_calls=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START,StateGraph\n",
    "from langgraph.prebuilt import tools_condition, ToolNode\n",
    "from IPython.display import Image,display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expected a Runnable, callable or dict.Instead got an unsupported type: <class 'str'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m builder\u001b[38;5;241m.\u001b[39madd_node(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent_creator\u001b[39m\u001b[38;5;124m\"\u001b[39m, ToolNode([content_creator]))\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Define the conditional edge based on the tool call from the LLM\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_conditional_edges\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLLM\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtitle_generate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtitle_generate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# If the tool call is 'title_generate', route to the title_generate node\u001b[39;49;00m\n\u001b[0;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent_creator\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent_creator\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# If the tool call is 'content_creator', route to the content_creator node\u001b[39;49;00m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Define the edges to represent the sequence of the process\u001b[39;00m\n\u001b[0;32m     21\u001b[0m builder\u001b[38;5;241m.\u001b[39madd_edge(START, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLLM\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Start to LLM node\u001b[39;00m\n",
      "File \u001b[1;32md:\\AgenticAI\\Live\\Agentic_AI\\venv\\Lib\\site-packages\\langgraph\\graph\\graph.py:290\u001b[0m, in \u001b[0;36mGraph.add_conditional_edges\u001b[1;34m(self, source, path, path_map, then)\u001b[0m\n\u001b[0;32m    288\u001b[0m     path_map_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;66;03m# find a name for the condition\u001b[39;00m\n\u001b[1;32m--> 290\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[43mcoerce_to_runnable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    291\u001b[0m name \u001b[38;5;241m=\u001b[39m path\u001b[38;5;241m.\u001b[39mname \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcondition\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    292\u001b[0m \u001b[38;5;66;03m# validate the condition\u001b[39;00m\n",
      "File \u001b[1;32md:\\AgenticAI\\Live\\Agentic_AI\\venv\\Lib\\site-packages\\langgraph\\utils\\runnable.py:427\u001b[0m, in \u001b[0;36mcoerce_to_runnable\u001b[1;34m(thing, name, trace)\u001b[0m\n\u001b[0;32m    420\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m RunnableCallable(\n\u001b[0;32m    421\u001b[0m             thing,\n\u001b[0;32m    422\u001b[0m             wraps(thing)(partial(run_in_executor, \u001b[38;5;28;01mNone\u001b[39;00m, thing)),  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    423\u001b[0m             name\u001b[38;5;241m=\u001b[39mname,\n\u001b[0;32m    424\u001b[0m             trace\u001b[38;5;241m=\u001b[39mtrace,\n\u001b[0;32m    425\u001b[0m         )\n\u001b[0;32m    426\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(thing, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m--> 427\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mRunnableParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthing\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    428\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    429\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    430\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected a Runnable, callable or dict.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    431\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInstead got an unsupported type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(thing)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    432\u001b[0m     )\n",
      "File \u001b[1;32md:\\AgenticAI\\Live\\Agentic_AI\\venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3541\u001b[0m, in \u001b[0;36mRunnableParallel.__init__\u001b[1;34m(self, steps__, **kwargs)\u001b[0m\n\u001b[0;32m   3538\u001b[0m merged \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msteps__} \u001b[38;5;28;01mif\u001b[39;00m steps__ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[0;32m   3539\u001b[0m merged\u001b[38;5;241m.\u001b[39mupdate(kwargs)\n\u001b[0;32m   3540\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m-> 3541\u001b[0m     steps__\u001b[38;5;241m=\u001b[39m{key: \u001b[43mcoerce_to_runnable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m key, r \u001b[38;5;129;01min\u001b[39;00m merged\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m   3542\u001b[0m )\n",
      "File \u001b[1;32md:\\AgenticAI\\Live\\Agentic_AI\\venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:5848\u001b[0m, in \u001b[0;36mcoerce_to_runnable\u001b[1;34m(thing)\u001b[0m\n\u001b[0;32m   5843\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   5844\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   5845\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected a Runnable, callable or dict.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   5846\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInstead got an unsupported type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(thing)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   5847\u001b[0m     )\n\u001b[1;32m-> 5848\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n",
      "\u001b[1;31mTypeError\u001b[0m: Expected a Runnable, callable or dict.Instead got an unsupported type: <class 'str'>"
     ]
    }
   ],
   "source": [
    "# Initialize the builder for the graph\n",
    "builder = StateGraph(State)\n",
    "\n",
    "# Add the LLM node that now uses llm_with_tools\n",
    "builder.add_node(\"LLM\", llm_with_tools)\n",
    "\n",
    "# Add the tools as nodes (title_generate and content_creator)\n",
    "builder.add_node(\"title_generate\", ToolNode([title_generate]))\n",
    "builder.add_node(\"content_creator\", ToolNode([content_creator]))\n",
    "\n",
    "# Define the conditional edge based on the tool call from the LLM\n",
    "builder.add_conditional_edges(\n",
    "    \"LLM\", \n",
    "    {\n",
    "        \"title_generate\": \"title_generate\",  # If the tool call is 'title_generate', route to the title_generate node\n",
    "        \"content_creator\": \"content_creator\"  # If the tool call is 'content_creator', route to the content_creator node\n",
    "    }\n",
    ")\n",
    "\n",
    "# Define the edges to represent the sequence of the process\n",
    "builder.add_edge(START, \"LLM\")  # Start to LLM node\n",
    "\n",
    "builder.add_edge(\"LLM\", \"title_generate\")  # LLM to title generation\n",
    "builder.add_edge(\"title_generate\", \"content_creator\")  # Title generation to content creation\n",
    "builder.add_edge(\"content_creator\", \"LLM\")  # Content creation back to LLM for possible further actions\n",
    "\n",
    "# End node (if any)\n",
    "builder.add_edge(\"LLM\", \"END\")\n",
    "\n",
    "# Compile the graph\n",
    "react_graph = builder.compile()\n",
    "\n",
    "# Display the graph as a Mermaid diagram (assuming you have `mermaid` installed)\n",
    "display(Image(react_graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "from typing import Annotated\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model='gpt-4')\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list[BaseMessage], add_messages]\n",
    "\n",
    "# Define the title generation function\n",
    "def title_generate(topic: str) -> str:\n",
    "    \"\"\"\n",
    "    Generates a catchy, informative, and creative title for an article based on the given topic.\n",
    "    \n",
    "    Args:\n",
    "        topic (str): The topic or subject for the article.\n",
    "    \n",
    "    Returns:\n",
    "        str: The generated title.\n",
    "    \"\"\"\n",
    "    prompt = f\"Generate a catchy, informative, and creative title for an article based on the following topic: {topic}\"\n",
    "    \n",
    "    response = llm.invoke([HumanMessage(content=prompt)])\n",
    "    \n",
    "    title = response.content\n",
    "    return title\n",
    "\n",
    "# Define the content creation function\n",
    "def content_creator(title: str) -> str:\n",
    "    \"\"\"\n",
    "    Generates a detailed and engaging article based on the given title.\n",
    "    \n",
    "    Args:\n",
    "        title (str): The title of the article to generate content for.\n",
    "    \n",
    "    Returns:\n",
    "        str: The generated content for the article.\n",
    "    \"\"\"\n",
    "    prompt = f\"Generate a detailed and engaging article based on the following title: {title}\"\n",
    "    \n",
    "    response = llm.invoke([HumanMessage(content=prompt)])\n",
    "    \n",
    "    content = response.content\n",
    "    return content\n",
    "\n",
    "tools = [title_generate, content_creator]\n",
    "llm_with_tools = llm.bind_tools(tools=tools, parallel_tool_calls=False)\n",
    "\n",
    "from langgraph.graph import START, StateGraph\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Initialize the builder for the graph\n",
    "builder = StateGraph(State)\n",
    "\n",
    "# Add the LLM node that now uses llm_with_tools\n",
    "builder.add_node(\"LLM\", llm_with_tools)\n",
    "\n",
    "# Add the tools as nodes \n",
    "builder.add_node(\"tools\",ToolNode(tools))\n",
    "\n",
    "# Define the conditional edge based on the tool call from the LLM\n",
    "builder.add_conditional_edges(\n",
    "    \"LLM\", \n",
    "    # If the latest message (result) from assistant is a tool call -> tools_condition routes to tools\n",
    "    # If the latest message (result) from assistant is a not a tool call -> tools_condition routes to END\n",
    "    tools_condition,\n",
    ")\n",
    "\n",
    "# Define the edges to represent the sequence of the process\n",
    "builder.add_edge(START, \"LLM\")  # Start to LLM node\n",
    "builder.add_edge(\"tools\", \"LLM\")  # Content creation back to LLM for possible further actions\n",
    "\n",
    "# Compile the graph\n",
    "react_graph = builder.compile()\n",
    "\n",
    "# Display the graph as a Mermaid diagram (assuming you have `mermaid` installed)\n",
    "display(Image(react_graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages=[HumanMessage(content=\"Generate a content for topic Machine Learning\")]\n",
    "messages=react_graph.invoke({\"messages\":messages})\n",
    "for m in messages[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'branch:LLM:tools_condition:END'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 61\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# Test the flow\u001b[39;00m\n\u001b[0;32m     60\u001b[0m messages \u001b[38;5;241m=\u001b[39m [HumanMessage(content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerate a content for topic Machine Learning\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[1;32m---> 61\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mreact_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m msg \u001b[38;5;129;01min\u001b[39;00m result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28mprint\u001b[39m(msg\u001b[38;5;241m.\u001b[39mcontent)\n",
      "File \u001b[1;32md:\\AgenticAI\\Live\\Agentic_AI\\venv\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2124\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[0m\n\u001b[0;32m   2122\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2123\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m-> 2124\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2125\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2128\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2129\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2130\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2131\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2132\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2133\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   2134\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalues\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[0;32m   2135\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlatest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "File \u001b[1;32md:\\AgenticAI\\Live\\Agentic_AI\\venv\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:1778\u001b[0m, in \u001b[0;36mPregel.stream\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[0;32m   1772\u001b[0m     get_waiter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m   1773\u001b[0m \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[0;32m   1774\u001b[0m \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates.\u001b[39;00m\n\u001b[0;32m   1775\u001b[0m \u001b[38;5;66;03m# Channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[0;32m   1776\u001b[0m \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[0;32m   1777\u001b[0m \u001b[38;5;66;03m# with channel updates applied only at the transition between steps.\u001b[39;00m\n\u001b[1;32m-> 1778\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_channels\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1779\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mtick(\n\u001b[0;32m   1780\u001b[0m         loop\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[0;32m   1781\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1784\u001b[0m     ):\n\u001b[0;32m   1785\u001b[0m         \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[0;32m   1786\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m output()\n",
      "File \u001b[1;32md:\\AgenticAI\\Live\\Agentic_AI\\venv\\Lib\\site-packages\\langgraph\\pregel\\loop.py:427\u001b[0m, in \u001b[0;36mPregelLoop.tick\u001b[1;34m(self, input_keys)\u001b[0m\n\u001b[0;32m    425\u001b[0m \u001b[38;5;66;03m# apply writes to managed values\u001b[39;00m\n\u001b[0;32m    426\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, values \u001b[38;5;129;01min\u001b[39;00m mv_writes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 427\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_mv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    428\u001b[0m \u001b[38;5;66;03m# produce values output\u001b[39;00m\n\u001b[0;32m    429\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_emit(\n\u001b[0;32m    430\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m, map_output_values, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_keys, writes, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchannels\n\u001b[0;32m    431\u001b[0m )\n",
      "File \u001b[1;32md:\\AgenticAI\\Live\\Agentic_AI\\venv\\Lib\\site-packages\\langgraph\\pregel\\loop.py:891\u001b[0m, in \u001b[0;36mSyncPregelLoop._update_mv\u001b[1;34m(self, key, values)\u001b[0m\n\u001b[0;32m    890\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_update_mv\u001b[39m(\u001b[38;5;28mself\u001b[39m, key: \u001b[38;5;28mstr\u001b[39m, values: Sequence[Any]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 891\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubmit(cast(WritableManagedValue, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmanaged\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m)\u001b[38;5;241m.\u001b[39mupdate, values)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'branch:LLM:tools_condition:END'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "from typing import Annotated\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, ToolMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model='gpt-4')\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list[BaseMessage], add_messages]\n",
    "\n",
    "# Define the tools (title_generate and content_creator remain the same)\n",
    "\n",
    "tools = [title_generate, content_creator]\n",
    "llm_with_tools = llm.bind_tools(tools=tools)\n",
    "\n",
    "from langgraph.graph import StateGraph, START\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "# Initialize the graph\n",
    "builder = StateGraph(State)\n",
    "\n",
    "# Define LLM node\n",
    "def llm_node(state: State):\n",
    "    messages = state['messages']\n",
    "    response = llm_with_tools.invoke(messages)\n",
    "    return {'messages': [response]}\n",
    "\n",
    "builder.add_node(\"LLM\", llm_node)\n",
    "\n",
    "# Add tools node\n",
    "tool_node = ToolNode(tools)\n",
    "builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "# Define conditional edges\n",
    "def tools_condition(state: State):\n",
    "    last_msg = state['messages'][-1]\n",
    "    if isinstance(last_msg, AIMessage) and last_msg.tool_calls:\n",
    "        return \"tools\"\n",
    "    else:\n",
    "        return \"END\"\n",
    "\n",
    "builder.add_conditional_edges(\"LLM\", tools_condition)\n",
    "\n",
    "# Define edges\n",
    "builder.add_edge(START, \"LLM\")\n",
    "builder.add_edge(\"tools\", \"LLM\")  # Loop back to LLM after tool execution\n",
    "\n",
    "# Compile the graph\n",
    "react_graph = builder.compile()\n",
    "\n",
    "# Test the flow\n",
    "messages = [HumanMessage(content=\"Generate a content for topic Machine Learning\")]\n",
    "result = react_graph.invoke({\"messages\": messages})\n",
    "\n",
    "for msg in result[\"messages\"]:\n",
    "    print(msg.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
