{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x00000205B844DBE0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x00000205B844ECC0>, model_name='gemma2-9b-it', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model=ChatGroq(model=\"gemma2-9b-it\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! ðŸ‘‹  How can I help you today? ðŸ˜Š\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 11, 'total_tokens': 26, 'completion_time': 0.027272727, 'prompt_time': 0.001939299, 'queue_time': 0.234349732, 'total_time': 0.029212026}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-e0978bea-879f-49a4-b81f-1d144199363a-0', usage_metadata={'input_tokens': 11, 'output_tokens': 15, 'total_tokens': 26})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hi Bala, it's nice to meet you! ðŸ‘‹\\n\\nI'm glad you're here. What can I do for you today? Are you working on any interesting projects you'd like to discuss? Perhaps you have a question about a specific data science topic? \\n\\nI'm ready to help in any way I can. ðŸ˜Š\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 74, 'prompt_tokens': 21, 'total_tokens': 95, 'completion_time': 0.134545455, 'prompt_time': 0.002116119, 'queue_time': 0.234738932, 'total_time': 0.136661574}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-f3afaccd-adfd-4125-9518-c03b76ab2e4a-0', usage_metadata={'input_tokens': 21, 'output_tokens': 74, 'total_tokens': 95})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage,SystemMessage\n",
    "\n",
    "model.invoke([HumanMessage(content=\"Hi, My name is Bala and I am a Data Scientist\")])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"You told me your name is Bala! ðŸ˜Š  Is there anything I can help you with today?  Perhaps you'd like to discuss a data science project, or maybe you have a question about a particular algorithm?\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 47, 'prompt_tokens': 47, 'total_tokens': 94, 'completion_time': 0.085454545, 'prompt_time': 0.002891038, 'queue_time': 0.23749301299999998, 'total_time': 0.088345583}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-028f53ca-0d86-4ef0-9c4e-e71da58455d3-0', usage_metadata={'input_tokens': 47, 'output_tokens': 47, 'total_tokens': 94})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "model.invoke([HumanMessage(content=\"Hi, My name is Bala and I am a Data Scientist\"),\n",
    "              AIMessage(content=\"Hi Bala, How are you ?\"),\n",
    "              HumanMessage(content=\"Am fine, Can you tell my name ?\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The above method is not the right option to store the chat history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store={}\n",
    "\n",
    "\"\"\"\n",
    "ChatMessageHistory -> is a single chat history\n",
    "BaseChatMessageHistory -> is a collection of chat history\n",
    "\"\"\"\n",
    "\n",
    "def get_session_history(session_id:str)-> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "\n",
    "    return store[session_id]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableWithMessageHistory(bound=RunnableBinding(bound=RunnableBinding(bound=RunnableLambda(_enter_history), kwargs={}, config={'run_name': 'load_history'}, config_factories=[])\n",
       "| RunnableBinding(bound=RunnableLambda(_call_runnable_sync), kwargs={}, config={'run_name': 'check_sync_or_async'}, config_factories=[]), kwargs={}, config={'run_name': 'RunnableWithMessageHistory'}, config_factories=[]), kwargs={}, config={}, config_factories=[], get_session_history=<function get_session_history at 0x00000205B8328EA0>, history_factory_config=[ConfigurableFieldSpec(id='session_id', annotation=<class 'str'>, name='Session ID', description='Unique identifier for a session.', default='', is_shared=True, dependencies=None)])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history=RunnableWithMessageHistory(model,get_session_history)\n",
    "with_message_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hi Bala, it's nice to meet you!  \\n\\nAs a large language model, I'm always interested in learning about people who work in data science. What kind of projects are you working on these days? \\n\\nDo you have a particular area of data science that you specialize in?\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 64, 'prompt_tokens': 20, 'total_tokens': 84, 'completion_time': 0.116363636, 'prompt_time': 0.001975969, 'queue_time': 0.232968322, 'total_time': 0.118339605}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-9c2438d0-4160-435f-a10c-4c8718e22e9c-0', usage_metadata={'input_tokens': 20, 'output_tokens': 64, 'total_tokens': 84})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config={\"configurable\":{\"session_id\":\"Bala\"}}\n",
    "\n",
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi, My name is Bala and I a Data Scientist\")],\n",
    "    config=config\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Bala. ðŸ˜Š  I remember that from our introduction!  \\n\\n\\nIs there anything else I can help you with today?\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 30, 'prompt_tokens': 96, 'total_tokens': 126, 'completion_time': 0.054545455, 'prompt_time': 0.005327807, 'queue_time': 0.23634481400000001, 'total_time': 0.059873262}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-13b9011f-a701-4fb7-8db7-3c91b54451f5-0', usage_metadata={'input_tokens': 96, 'output_tokens': 30, 'total_tokens': 126})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response1=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What is my name\")],\n",
    "    config=config\n",
    ")\n",
    "\n",
    "response1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"As an AI, I have no memory of past conversations and do not know your name. If you'd like to tell me, I'm happy to know! ðŸ˜Š\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 38, 'prompt_tokens': 13, 'total_tokens': 51, 'completion_time': 0.069090909, 'prompt_time': 0.001908449, 'queue_time': 0.236288432, 'total_time': 0.070999358}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-fa9f85c2-6586-459a-920e-9a347555a0c0-0', usage_metadata={'input_tokens': 13, 'output_tokens': 38, 'total_tokens': 51})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config={\"configurable\":{\"session_id\":\"Ramya\"}}\n",
    "\n",
    "response2=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What is my name\")],\n",
    "    config=config\n",
    ")\n",
    "response2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='As an AI, I have no memory of past conversations. Every interaction we have is fresh and new.\\n\\nWhat can I help you with today? ðŸ˜Š  \\n\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 36, 'prompt_tokens': 66, 'total_tokens': 102, 'completion_time': 0.065454545, 'prompt_time': 0.003836788, 'queue_time': 0.23851241299999998, 'total_time': 0.069291333}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-bba9be0f-f926-4f62-ad13-1907e7a71787-0', usage_metadata={'input_tokens': 66, 'output_tokens': 36, 'total_tokens': 102})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response2=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What did I ask you earlier?\")],\n",
    "    config=config\n",
    ")\n",
    "response2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InMemoryChatMessageHistory(messages=[HumanMessage(content='Hi, My name is Bala and I a Data Scientist', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hi Bala, it's nice to meet you!  \\n\\nAs a large language model, I'm always interested in learning about people who work in data science. What kind of projects are you working on these days? \\n\\nDo you have a particular area of data science that you specialize in?\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 64, 'prompt_tokens': 20, 'total_tokens': 84, 'completion_time': 0.116363636, 'prompt_time': 0.001975969, 'queue_time': 0.232968322, 'total_time': 0.118339605}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-9c2438d0-4160-435f-a10c-4c8718e22e9c-0', usage_metadata={'input_tokens': 20, 'output_tokens': 64, 'total_tokens': 84}), HumanMessage(content='What is my name', additional_kwargs={}, response_metadata={}), AIMessage(content='Your name is Bala. ðŸ˜Š  I remember that from our introduction!  \\n\\n\\nIs there anything else I can help you with today?\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 30, 'prompt_tokens': 96, 'total_tokens': 126, 'completion_time': 0.054545455, 'prompt_time': 0.005327807, 'queue_time': 0.23634481400000001, 'total_time': 0.059873262}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-13b9011f-a701-4fb7-8db7-3c91b54451f5-0', usage_metadata={'input_tokens': 96, 'output_tokens': 30, 'total_tokens': 126})])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_session_history(\"Bala\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InMemoryChatMessageHistory(messages=[HumanMessage(content='What is my name', additional_kwargs={}, response_metadata={}), AIMessage(content=\"As an AI, I have no memory of past conversations and do not know your name. If you'd like to tell me, I'm happy to know! ðŸ˜Š\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 38, 'prompt_tokens': 13, 'total_tokens': 51, 'completion_time': 0.069090909, 'prompt_time': 0.001908449, 'queue_time': 0.236288432, 'total_time': 0.070999358}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-fa9f85c2-6586-459a-920e-9a347555a0c0-0', usage_metadata={'input_tokens': 13, 'output_tokens': 38, 'total_tokens': 51}), HumanMessage(content='What did I ask you earlier?', additional_kwargs={}, response_metadata={}), AIMessage(content='As an AI, I have no memory of past conversations. Every interaction we have is fresh and new.\\n\\nWhat can I help you with today? ðŸ˜Š  \\n\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 36, 'prompt_tokens': 66, 'total_tokens': 102, 'completion_time': 0.065454545, 'prompt_time': 0.003836788, 'queue_time': 0.23851241299999998, 'total_time': 0.069291333}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-bba9be0f-f926-4f62-ad13-1907e7a71787-0', usage_metadata={'input_tokens': 66, 'output_tokens': 36, 'total_tokens': 102})])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_session_history(\"Ramya\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"That's cool, Jhon Cena!  \\n\\nVanilla ice cream is a classic for a reason. It's delicious and goes well with so many things.  \\n\\nWhat's your favorite way to enjoy vanilla ice cream? ðŸ¦\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 52, 'prompt_tokens': 22, 'total_tokens': 74, 'completion_time': 0.094545455, 'prompt_time': 0.002135388, 'queue_time': 0.23419699300000002, 'total_time': 0.096680843}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-dcdc906e-19b6-471e-8a9e-55c9c96139b7-0', usage_metadata={'input_tokens': 22, 'output_tokens': 52, 'total_tokens': 74})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config2={\"configurable\":{\"session_id\":\"Jhon\"}}\n",
    "\n",
    "response3=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"My name is Jhon Cena and I like Vannila Ice cream\")],\n",
    "    config=config2\n",
    ")\n",
    "\n",
    "response3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"You told me your name is Jhon Cena! ðŸ˜Š  \\n\\nIs there something else you'd like to talk about? \\n\\n\\n\\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 30, 'prompt_tokens': 86, 'total_tokens': 116, 'completion_time': 0.054545455, 'prompt_time': 0.004158838, 'queue_time': 0.236340641, 'total_time': 0.058704293}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-064a7cc0-1e83-460e-bd85-b85e0e2543be-0', usage_metadata={'input_tokens': 86, 'output_tokens': 30, 'total_tokens': 116})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config2={\"configurable\":{\"session_id\":\"Jhon\"}}\n",
    "\n",
    "response4=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What is my name\")],\n",
    "    config=config2\n",
    ")\n",
    "\n",
    "response4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='You said your favorite item is vanilla ice cream! ðŸ¦  \\n\\nDo you want to tell me more about it? What do you like best about it?  \\n\\n\\n\\n\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 37, 'prompt_tokens': 127, 'total_tokens': 164, 'completion_time': 0.067272727, 'prompt_time': 0.005601477, 'queue_time': 0.237382632, 'total_time': 0.072874204}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-72d66255-4163-46d0-aa6f-96043eb14dbf-0', usage_metadata={'input_tokens': 127, 'output_tokens': 37, 'total_tokens': 164})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config2={\"configurable\":{\"session_id\":\"Jhon\"}}\n",
    "\n",
    "response5=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What is favourite item\")],\n",
    "    config=config2\n",
    ")\n",
    "\n",
    "response5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt1=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are a helpful assistant. Answer all the question to the best of your ability\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "new_chain=prompt1|model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello Bala! ðŸ‘‹\\n\\nNice to meet you. How can I be helpful today? ðŸ˜Š  \\n\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 30, 'total_tokens': 53, 'completion_time': 0.041818182, 'prompt_time': 0.002148438, 'queue_time': 0.236594756, 'total_time': 0.04396662}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-8a249c20-e34e-4371-81b3-5182b474e021-0', usage_metadata={'input_tokens': 30, 'output_tokens': 23, 'total_tokens': 53})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_chain.invoke({\"messages\":[HumanMessage(content=\"Hi My name is Bala\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history=RunnableWithMessageHistory(new_chain,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hi Bala, it's nice to meet you!  ðŸ‘‹\\n\\nI'm happy to help with any questions you have. Just ask away! ðŸ˜Š  \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 35, 'prompt_tokens': 30, 'total_tokens': 65, 'completion_time': 0.063636364, 'prompt_time': 0.002260489, 'queue_time': 0.29812983200000004, 'total_time': 0.065896853}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-69b50d12-28e0-401b-af05-3bf5b26acf1c-0', usage_metadata={'input_tokens': 30, 'output_tokens': 35, 'total_tokens': 65})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config3={\"configurable\":{\"session_id\":\"chat4\"}}\n",
    "\n",
    "response5=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi My name is Bala\")],\n",
    "    config=config3\n",
    ")\n",
    "\n",
    "response5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translator Prompt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='à®µà®£à®•à¯à®•à®®à¯ Bala! ðŸ˜Š \\n\\nà®¨à®¾à®©à¯ à®‰à®™à¯à®•à®³à¯à®•à¯à®•à¯ à®‰à®¤à®µà¯à®µà®¤à®¿à®²à¯ à®®à®•à®¿à®´à¯à®šà¯à®šà®¿ à®…à®Ÿà¯ˆà®•à®¿à®±à¯‡à®©à¯. à®Žà®©à¯à®© à®µà®¿à®©à®¾à®•à¯à®•à®³à¯ à®‡à®°à¯à®•à¯à®•à®¿à®©à¯à®±à®©? \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 48, 'prompt_tokens': 31, 'total_tokens': 79, 'completion_time': 0.087272727, 'prompt_time': 0.002380719, 'queue_time': 0.23949289199999999, 'total_time': 0.089653446}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-2740f97e-d5a3-4562-bbab-0c4309a8be0b-0', usage_metadata={'input_tokens': 31, 'output_tokens': 48, 'total_tokens': 79})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt2=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are a helpful assistant. Answer the questions to the best of your ability in {language}\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "new_chain1=prompt2|model\n",
    "new_chain1.invoke({\"messages\":[HumanMessage(content=\"Hi My name is Bala\")],\"language\":\"Tamil\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trimming - use when we need to trim the long history of conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\AgenticAI\\Live\\Agentic_AI\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"you're a good assistant\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content=\"Hi! I'm Bala\", additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Hi!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='I like Vannila Ice Cream', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='nice', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='whats 2+2', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='4', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Thanks', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='No Problem', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Having Fun', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Yes!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage,trim_messages\n",
    "\n",
    "trimmer=trim_messages(\n",
    "    max_tokens=60,\n",
    "    strategy=\"last\",\n",
    "    token_counter=model,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\"\n",
    ")\n",
    "\n",
    "messages=[\n",
    "    SystemMessage(content=\"you're a good assistant\"),\n",
    "    HumanMessage(content=\"Hi! I'm Bala\"),\n",
    "    AIMessage(content=\"Hi!\"),\n",
    "    HumanMessage(content=\"I like Vannila Ice Cream\"),\n",
    "    AIMessage(content=\"nice\"),\n",
    "    HumanMessage(content=\"whats 2+2\"),\n",
    "    AIMessage(content=\"4\"),\n",
    "    HumanMessage(content=\"Thanks\"),\n",
    "    AIMessage(content=\"No Problem\"),\n",
    "    HumanMessage(content=\"Having Fun\"),\n",
    "    AIMessage(content=\"Yes!\")\n",
    "]\n",
    "\n",
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step followed in below cell\n",
    "- Getting chat history from messages\n",
    "- importing messages in itemgetter\n",
    "- Using trimmer to trim the chat history\n",
    "- creating chains for messgaes | trimmer | prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableAssign(mapper={\n",
       "  messages: RunnableLambda(itemgetter('messages'))\n",
       "            | RunnableLambda(...)\n",
       "})\n",
       "| ChatPromptTemplate(input_variables=['language', 'messages'], input_types={'messages': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x00000205B78BD580>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['language'], input_types={}, partial_variables={}, template='You are a helpful assistant. Answer the questions to the best of your ability in {language}'), additional_kwargs={}), MessagesPlaceholder(variable_name='messages')])\n",
       "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x00000205B844DBE0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x00000205B844ECC0>, model_name='gemma2-9b-it', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "trim_chain=(RunnablePassthrough.assign(messages=itemgetter(\"messages\") | trimmer) | prompt2 | model )\n",
    "trim_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='You said you like **Vannila Ice Cream**. ðŸ˜‹  \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 99, 'total_tokens': 114, 'completion_time': 0.027272727, 'prompt_time': 0.004305366, 'queue_time': 0.238107473, 'total_time': 0.031578093}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-91abcfd0-5f89-4a0f-827b-9bf943368d84-0', usage_metadata={'input_tokens': 99, 'output_tokens': 15, 'total_tokens': 114})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=trim_chain.invoke(\n",
    "    {\n",
    "        \"messages\":messages + [HumanMessage(content=\"What ice cream do i like\")],\n",
    "        \"language\":\"Malayalam\"\n",
    "    }\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
